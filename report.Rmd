---
title: "Fit and Predict"
author: "AV"
date: "06/18/2015"
output: html_document
---

```{r echo=FALSE}
library(caret)
library(doParallel)
set.seed(1234)
```

# Background

Using devices such as **Jawbone Up**, **Nike FuelBand**, and **Fitbit** it is now possible to collect a large amount
of data about personal activity relatively inexpensively. These type of devices are part of the quantified self
movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to
find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify
how much of a particular activity they do, but they rarely quantify how well they do it. In this project, we
will use data from accelerometers on the

* belt
* forearm
* arm and
* dumbell

of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways:

1. sitting down
2. standing up
3. walking
4. standing
5. sitting

More information is available from the website here: http://groupware.les.inf.puc-rio.br/har. 

# Objective

The goal is to predict the manner in which the 6 persons did the exercise. This is the *classe* variable in
the training set. Moreover, the prediction model should be used to predict 20 different test cases.

# Cleaning the Training Set

```{r}
training_set <- read.csv("pml-training.csv", na.strings = c("", "NA", "#DIV/0!", '""'))
testing_set  <- read.csv("pml-testing.csv",  na.strings = c("", "NA", "#DIV/0!", '""'))

dim(training_set)
dim(testing_set)
```

After looking to the content of the training data set, we proceed by

1. Removing unused variables (i.e. data not needed to predict the *classe*)
2. Remove variables with low variance
3. Remove variables with all NA

```{r}
training_set <- training_set[, -grep("X|user_name|timestamp|new_window|num_window", names(training_set))]
training_set <- training_set[, -nearZeroVar(training_set)]
training_set <- training_set[, apply(training_set, 2, function(x) !any(is.na(x)))]

dim(training_set)
```

# Training

Wefirst split the **training set** into two halves: the **training subset** and the **testing subset**

```{r}
index = createDataPartition(y = training_set$classe, p=0.5, list=FALSE)
training_subset <- training_set[index,]
testing_subset <- training_set [-index,]
```

Then we create the model

1. processing the **training subset**
2. using the *Random Forest* and
3. running a five fold cross validation
4. using the package *doParallel*.

```{r}
parallelCluster <- makeCluster(detectCores())
registerDoParallel(parallelCluster)

rf_model <- train(classe ~ .,
                  data = training_subset,
                  method = "rf",
                  trControl = trainControl(method = "cv", number = 5, allowParallel = TRUE) )

stopCluster(parallelCluster)
```

The resulting fial model is the following:

```{r}
rf_model$finalModel
```

with accuracy

```{r}
rf_model
```

# Validation

We use our model to predict the outcome *classe* in the **training subset**:

```{r}
confusionMatrix (predict(rf_model, training_subset), training_subset$classe)
```

and then, finally, on the **testing subset**:

```{r}
confusionMatrix (predict(rf_model, testing_subset), testing_subset$classe)
```

# Prediction

Here we use the model to predict the outcome on the original **testing set**

```{r}
predictions <- predict(rf_model, testing_set)
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(predictions)
```